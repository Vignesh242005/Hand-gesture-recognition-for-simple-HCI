# Virtual-Mouse-Using-MediaPipe

# Abstract

A gesture-based system using MediaPipe and OpenCV replaces mouse inputs, enabling intuitive, hands-free control for enhanced accessibility.  

# Need for the Project

The need for a gesture-based navigation system stems from the following challenges in traditional human-computer interaction methods:

1. **Accessibility Issues**: Conventional input devices like mice and keyboards may not be suitable for individuals with physical disabilities or in environments where physical contact is not feasible.
2. **Ergonomics**: Prolonged use of mice and keyboards can lead to strain-related injuries such as carpal tunnel syndrome.
3. **Hands-Free Interaction**: Fields like surgery, presentations, or remote operations require seamless interaction without physical contact with devices.
4. **Modern User Experience**: The demand for intuitive, contactless, and futuristic interfaces continues to grow, necessitating innovation in interaction technology.

This project addresses these gaps by providing a hands-free, intuitive, and ergonomic solution that uses real-time hand gesture recognition.

---

# Explanation of the Project

This project introduces a **gesture-based navigation system** that leverages MediaPipe's Hand Landmark and Gesture Recognition models along with OpenCV for real-time processing. It serves as a replacement for traditional mouse inputs, allowing users to interact with a computer using simple hand gestures. Key features include:

### Gesture Mapping to Functions
- **Pinch Right to Left**: Adjust screen brightness.
- **Call Me Sign**: Close application tabs.
- **V Sign**: Navigate the cursor on the screen.
- **Two Fingers Closed**: Perform double-click actions.
